LINGUANA TESTING GUIDE
======================

TESTING STRATEGY
----------------
1. Unit Tests: Individual functions and methods
2. Integration Tests: API endpoints and workflows
3. End-to-End Tests: Complete user journeys
4. Performance Tests: Load and stress testing
5. Security Tests: Authentication and authorization

BACKEND TESTING
===============

Setup Test Environment:
-----------------------
cd backend
source venv/bin/activate
export DJANGO_SETTINGS_MODULE=linguana.settings
export DATABASE_URL=postgresql://test_user:test_pass@localhost:5432/test_linguana

Run All Tests:
--------------
python manage.py test

Run Specific App Tests:
------------------------
python manage.py test users
python manage.py test audio
python manage.py test annotations
python manage.py test rewards

Run with Coverage:
------------------
pip install coverage
coverage run --source='.' manage.py test
coverage report
coverage html  # Generate HTML report

Sample Test Cases:
------------------

1. User Authentication Tests:
   - Test user registration
   - Test login with email/password
   - Test JWT token generation
   - Test wallet connection
   - Test Firebase authentication
   - Test magic link flow

2. Audio Clip Tests:
   - Test audio upload
   - Test file validation
   - Test waveform generation
   - Test ASR transcription
   - Test pronunciation feedback
   - Test clip deletion permissions

3. Annotation Tests:
   - Test annotation creation
   - Test consensus algorithm
   - Test Levenshtein similarity
   - Test annotation task assignment
   - Test validation workflow

4. Reward Tests:
   - Test reward creation
   - Test reward distribution
   - Test blockchain integration
   - Test withdrawal requests
   - Test balance updates

5. WebSocket Tests:
   - Test ASR streaming connection
   - Test real-time transcription
   - Test connection handling

Example Test File (users/tests.py):
------------------------------------
from django.test import TestCase
from django.contrib.auth import get_user_model
from rest_framework.test import APIClient
from rest_framework import status

User = get_user_model()

class UserAuthenticationTests(TestCase):
    def setUp(self):
        self.client = APIClient()
        self.register_url = '/api/auth/register/'
        self.login_url = '/api/auth/login/'
        
    def test_user_registration(self):
        data = {
            'username': 'testuser',
            'email': 'test@example.com',
            'password': 'TestPass123!',
            'password_confirm': 'TestPass123!'
        }
        response = self.client.post(self.register_url, data)
        self.assertEqual(response.status_code, status.HTTP_201_CREATED)
        self.assertIn('tokens', response.data)
        self.assertTrue(User.objects.filter(email='test@example.com').exists())
    
    def test_user_login(self):
        user = User.objects.create_user(
            username='testuser',
            email='test@example.com',
            password='TestPass123!'
        )
        data = {
            'email': 'test@example.com',
            'password': 'TestPass123!'
        }
        response = self.client.post(self.login_url, data)
        self.assertEqual(response.status_code, status.HTTP_200_OK)
        self.assertIn('tokens', response.data)

FRONTEND TESTING
================

Setup:
------
cd frontend
npm install

Run Tests:
----------
npm test
npm run test:watch
npm run test:coverage

Testing Libraries:
------------------
- Jest: Test runner
- React Testing Library: Component testing
- MSW: API mocking
- Playwright: E2E testing

Sample Test Cases:
------------------

1. Component Tests:
   - Test audio recorder component
   - Test waveform visualization
   - Test authentication forms
   - Test dashboard displays
   - Test badge/reward displays

2. Integration Tests:
   - Test audio upload flow
   - Test annotation workflow
   - Test wallet connection
   - Test reward claiming

3. E2E Tests:
   - Complete contributor journey
   - Complete validator journey
   - Reward distribution flow

Example Test (components/AudioRecorder.test.tsx):
--------------------------------------------------
import { render, screen, fireEvent } from '@testing-library/react'
import AudioRecorder from './AudioRecorder'

describe('AudioRecorder', () => {
  it('renders record button', () => {
    render(<AudioRecorder />)
    expect(screen.getByText('Start Recording')).toBeInTheDocument()
  })
  
  it('starts recording on button click', () => {
    render(<AudioRecorder />)
    const button = screen.getByText('Start Recording')
    fireEvent.click(button)
    expect(screen.getByText('Stop Recording')).toBeInTheDocument()
  })
})

ASR SERVICE TESTING
===================

Run Tests:
----------
cd asr_service
pytest

Test Cases:
-----------
1. Test Whisper model loading
2. Test audio transcription
3. Test streaming endpoint
4. Test benchmark calculation
5. Test error handling

Example Test (test_main.py):
-----------------------------
from fastapi.testclient import TestClient
from main import app

client = TestClient(app)

def test_health_check():
    response = client.get("/health")
    assert response.status_code == 200
    assert response.json()["status"] == "healthy"

def test_transcribe_audio():
    with open("test_audio.wav", "rb") as f:
        response = client.post(
            "/transcribe",
            files={"audio": f},
            data={"dialect": "sheng"}
        )
    assert response.status_code == 200
    assert "transcription" in response.json()

INTEGRATION TESTING
===================

Test Complete Workflows:
------------------------

1. Contributor Workflow:
   a. User registers
   b. User records audio
   c. Audio uploaded and processed
   d. ASR generates draft
   e. Pronunciation feedback generated
   f. Clip submitted for annotation
   g. Validators annotate
   h. Consensus reached
   i. Reward created
   j. USDC distributed

2. Validator Workflow:
   a. User logs in
   b. Fetches next annotation task
   c. Listens to audio
   d. Provides transcription
   e. Submits annotation
   f. Receives points
   g. Earns reward after consensus

3. Reward Distribution:
   a. Clip validated
   b. Rewards created (contributor + validators)
   c. Blockchain transaction sent
   d. Transaction verified
   e. User balance updated
   f. Transaction logged

Test Script Example:
--------------------
#!/bin/bash

echo "Testing complete workflow..."

# Register user
TOKEN=$(curl -X POST http://localhost:8000/api/auth/register/ \
  -H "Content-Type: application/json" \
  -d '{"username":"test","email":"test@test.com","password":"Test123!","password_confirm":"Test123!"}' \
  | jq -r '.tokens.access')

# Upload audio
curl -X POST http://localhost:8000/api/audio/clips/ \
  -H "Authorization: Bearer $TOKEN" \
  -F "audio_file=@test_audio.wav" \
  -F "dialect=sheng" \
  -F "consent_given=true"

echo "Workflow test complete"

PERFORMANCE TESTING
===================

Load Testing with Locust:
--------------------------
pip install locust

Create locustfile.py:
---------------------
from locust import HttpUser, task, between

class LinguanaUser(HttpUser):
    wait_time = between(1, 3)
    
    def on_start(self):
        response = self.client.post("/api/auth/login/", json={
            "email": "test@test.com",
            "password": "Test123!"
        })
        self.token = response.json()["tokens"]["access"]
    
    @task(3)
    def list_clips(self):
        self.client.get("/api/audio/clips/", headers={
            "Authorization": f"Bearer {self.token}"
        })
    
    @task(1)
    def get_profile(self):
        self.client.get("/api/auth/profile/", headers={
            "Authorization": f"Bearer {self.token}"
        })

Run Load Test:
--------------
locust -f locustfile.py --host=http://localhost:8000

Performance Benchmarks:
-----------------------
- API response time: < 200ms (p95)
- ASR transcription: < 2s for 5-8s clip
- WebSocket latency: < 100ms
- Database queries: < 50ms
- Concurrent users: 1000+

SECURITY TESTING
================

1. Authentication Tests:
   - Test JWT expiration
   - Test token refresh
   - Test invalid credentials
   - Test rate limiting

2. Authorization Tests:
   - Test role-based access
   - Test resource ownership
   - Test admin-only endpoints

3. Input Validation:
   - Test SQL injection
   - Test XSS attacks
   - Test file upload validation
   - Test CSRF protection

4. API Security:
   - Test CORS configuration
   - Test HTTPS enforcement
   - Test sensitive data exposure

Security Checklist:
-------------------
✓ All passwords hashed with bcrypt
✓ JWT tokens expire appropriately
✓ HTTPS enforced in production
✓ CORS configured correctly
✓ Rate limiting enabled
✓ Input validation on all endpoints
✓ SQL injection prevention
✓ XSS protection
✓ CSRF tokens validated
✓ File upload restrictions
✓ Sensitive data encrypted

CONTINUOUS INTEGRATION
======================

GitHub Actions Workflow (.github/workflows/test.yml):
------------------------------------------------------
name: Tests

on: [push, pull_request]

jobs:
  backend-tests:
    runs-on: ubuntu-latest
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_PASSWORD: postgres
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v3
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    - name: Install dependencies
      run: |
        cd backend
        pip install -r requirements.txt
    - name: Run tests
      run: |
        cd backend
        python manage.py test
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379/0

  frontend-tests:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    - name: Set up Node
      uses: actions/setup-node@v3
      with:
        node-version: '18'
    - name: Install dependencies
      run: |
        cd frontend
        npm install
    - name: Run tests
      run: |
        cd frontend
        npm test

MANUAL TESTING CHECKLIST
=========================

Before Release:
---------------
□ User registration works
□ Login with all methods works
□ Audio recording works
□ Audio upload works
□ Waveform displays correctly
□ ASR transcription works
□ Pronunciation feedback displays
□ Annotation workflow complete
□ Consensus algorithm correct
□ Rewards created correctly
□ Blockchain transactions work
□ Wallet connection works
□ Withdrawal requests work
□ Dashboard displays correctly
□ Leaderboard works
□ Badges awarded correctly
□ PWA installs correctly
□ Offline mode works
□ Push notifications work
□ Mobile responsive
□ Cross-browser compatible

DEBUGGING TIPS
==============

Backend:
--------
- Check logs: tail -f logs/linguana.log
- Django shell: python manage.py shell
- Database: python manage.py dbshell
- Celery tasks: celery -A linguana inspect active

Frontend:
---------
- Browser console for errors
- React DevTools for component state
- Network tab for API calls
- Redux DevTools for state management

ASR Service:
------------
- Check uvicorn logs
- Test with curl/Postman
- Monitor GPU usage
- Check model loading

Common Issues:
--------------
1. Database connection: Check DATABASE_URL
2. Redis connection: Ensure Redis running
3. Celery not processing: Check worker status
4. ASR timeout: Increase timeout or check service
5. CORS errors: Check CORS_ALLOWED_ORIGINS
6. File upload fails: Check MAX_UPLOAD_SIZE
7. Wallet connection fails: Check RPC URL
